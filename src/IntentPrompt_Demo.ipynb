{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c7dde36",
   "metadata": {},
   "source": [
    "# IntentPrompt Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dcd98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import time\n",
    "import pandas as pd\n",
    "from utils import (\n",
    "    check_mkdirs, subsample_data,\n",
    "    get_prompts_paraphrase, get_prompts_inquiry, get_prompts_evaluation, IA,\n",
    "    build_genai_model, generate_content, printf, compute_asr, compute_success_hscore_mean,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add80465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define arguments\n",
    "vertexai_proj_id = 'Input_your_VertexAI_Project_ID'\n",
    "vertexai_region = 'vertexai_region' # e.g., us-central1\n",
    "openai_key = 'Input_your_OpenAI_key'\n",
    "deepseek_key = 'Input_your_DeepSeek_key'\n",
    "anthropic_key = 'Input_your_Anthropic_key'\n",
    "openrouter_key = 'Input_your_OpenRouter_key'\n",
    "\n",
    "paraphraser_name = 'gemini-1.5-flash-002' # options: [gemini-1.5-flash-002, qwen/qwen3-14b:free, mistralai/mixtral-8x7b-instruct]\n",
    "target_name = 'gpt-4o' # options: [gpt-4o/gpt-4o-mini-2024-07-18, o1/o1-mini, o3-mini, gemini-2.0-flash-001, claude-3-7-sonnet-20250219/claude-3-haiku-20240307, deepseek-chat, deepseek-reasoner, qwen/qwen3-235b-a22b:free, meta-llama/llama-4-scout:free] # deepseek v3/r1\n",
    "evaluator_name = 'gemini-1.5-flash-002' # options: [gemini-1.5-flash-002, gpt-4o-mini-2024-07-18, qwen/qwen3-32b:free]\n",
    "para_types = 'none' # choose one type of paraphrase, options: ['none', 'ass', 'msw', 'ces']\n",
    "is_fuzzy = '' # whether or not obscure the intent, options: ['', 'NO']\n",
    "para_mode = 'fuzzy_struct' # the mode of paraphrase, options: ['revise', 'struct', 'fuzzy_struct']\n",
    "inq_mode = 'spin' # the mode of inquiry, options: ['naive', 'ela', 'spin']\n",
    "is_defense = False # defend with intent analysis or not, options: [True, False]\n",
    "max_tokens = 2048 # 8192/4096/2048\n",
    "temp = 0.8\n",
    "top_p = 0.95\n",
    "num_iter = 5 # the number of iterations for optimizing the prompts\n",
    "is_sampled = True # for debug mode\n",
    "num_sample = 20 # number of sampled data\n",
    "\n",
    "para_dict = {'none': 'taking no specific strategy',\n",
    "             'ass': 'altering sentence structure',\n",
    "             'msw': 'misspelling sensitive words',\n",
    "             'ces': 'changing expression style',\n",
    "            } # types of paraphrase\n",
    "pdict = {'inquiries': 'NA',\n",
    "         'para_strat': para_dict[para_types],\n",
    "         'fuzzy': is_fuzzy,\n",
    "         'para_inq_old': 'NA',\n",
    "         'feedback': 'NA',\n",
    "        } # prompts' arguments\n",
    "openai_models = ['gpt', 'o1', 'o3']\n",
    "openrouter_models = ['qwen', 'llama', 'mixtral']\n",
    "api_key_map = {model: openai_key for model in openai_models} | {\n",
    "               model: openrouter_key for model in openrouter_models} | {\n",
    "                'deepseek': deepseek_key,\n",
    "                'claude': anthropic_key,\n",
    "              } # map model to api key\n",
    "url_model_map = {\"https://api.openai.com/v1\": ['gpt', 'o1', 'o3'],\n",
    "                 \"https://api.deepseek.com/v1\": ['deepseek'],\n",
    "                 \"https://openrouter.ai/api/v1\": ['qwen', 'llama', 'mixtral'],\n",
    "                }\n",
    "genai_config = {'max_tokens': max_tokens,\n",
    "                'temperature': temp,\n",
    "                'top_p': top_p,\n",
    "                }\n",
    "#vertexai.init(project=vertexai_proj_id, location=vertexai_region)  # init() if necessary\n",
    "# Instructions for using Vertex AI:\n",
    "# gcloud init\n",
    "# gcloud auth application-default login\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173125e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Jailbreak through iterative intent manipulation.\n",
    "\n",
    "def intent_jailbreak(inquires_list: list, num_iter: int, verbose: bool) -> list:\n",
    "    \"\"\"\n",
    "    @topic: explore the vulnerability via intent jailbreak.\n",
    "    @inputs:\n",
    "        inquiries_list (list of string): a list of text inquiries.\n",
    "        num_iter (int): the number of iterations.\n",
    "        verbose (bool): print out the log if verbose=True.\n",
    "    @returns:\n",
    "        opt_para_inquiries (list): a list of optimal paraphrased inquiries for jailbreak.\n",
    "        asr_list (list): a list of attack success rates (ASR) for each inquiry.\n",
    "        hscore_list (list): a list of harmfulness scores (hscore) for each inquiry.\n",
    "        q4j_mean (float): the average number of queries used for a successful jailbreak.\n",
    "    \"\"\"\n",
    "    # Initialize multi-agents for jailbreak.\n",
    "    paraphraser = build_genai_model(paraphraser_name, api_key_map, url_model_map) # auxiliary agent\n",
    "    target_model = build_genai_model(target_name, api_key_map, url_model_map) # victim model\n",
    "    evaluator = build_genai_model(evaluator_name, api_key_map, url_model_map) # monitoring agent\n",
    "\n",
    "    opt_para_inquires = ['' for _ in range(len(inquires_list))]\n",
    "    asr_list, hscore_list = ([0] * len(inquires_list) for _ in range(2))\n",
    "    q4j_list = []\n",
    "    for i, inquiry in enumerate(inquires_list):\n",
    "        time.sleep(1)\n",
    "        printf(\"-\"*20, verbose)\n",
    "        printf(f\"Jailbreaking the {int(i+1)}-th inquiry: {inquiry}\", verbose)\n",
    "        pdict['inquires'] = inquiry\n",
    "        num_query4jailbreak = 1 # the number of queries used for a successful jailbreak.\n",
    "        for n in range(num_iter):\n",
    "            time.sleep(1)\n",
    "            printf(f\"Paraphrasing the inquiry in {int(n+1)}-th iteration.\", verbose)\n",
    "            # paraphrase the malicious inquires.\n",
    "            prompts_para = get_prompts_paraphrase(pdict, para_mode)  # update prompts for paraphrase\n",
    "            try:\n",
    "                para_inq = generate_content(paraphraser, paraphraser_name, genai_config, prompts_para)\n",
    "            except:\n",
    "                break # break if fail to paraphrase\n",
    "            printf(f\"Paraphrased inquires: {para_inq}\".strip(), verbose)\n",
    "\n",
    "            # generate response using the target model with paraphrased inquires.\n",
    "            prompts_inq = get_prompts_inquiry(para_inq, is_defense, IA, inq_mode)  # update prompts for inquires\n",
    "\n",
    "            resp = generate_content(target_model, target_name, genai_config, prompts_inq)\n",
    "            printf(f\"Response from the target model: {resp}\".strip(), verbose)\n",
    "\n",
    "            # evaluate the jailbreak performance: is successfully jailbroken? (0 or 1), harmfulness score (0-5).\n",
    "            prompts_eval = get_prompts_evaluation(para_inq, resp)  # update prompts for evaluation\n",
    "            res_eval = generate_content(evaluator, evaluator_name, genai_config, prompts_eval)\n",
    "            try:\n",
    "                is_jailbroken, hscore = eval(res_eval)\n",
    "            except:\n",
    "                print(f\"fail to evaluate the outputs in {n}-th iteration for the paraphrased inquiry '{para_inq}'.\")\n",
    "                is_jailbroken, hscore = 0, 0\n",
    "\n",
    "            printf(f\"Is_Success_Jailbreak: {is_jailbroken}, Harmfulness score: {hscore}.\", verbose)\n",
    "            if is_jailbroken == 0: # update 'para_inq_old' and 'feedback' for the next iteration if not success.\n",
    "                pdict['para_inq_old'] = para_inq\n",
    "                pdict['feedback'] = resp\n",
    "                num_query4jailbreak += 1\n",
    "            else: # break the current FOR loop if the jailbreak is successful.\n",
    "                printf(f\"Successful jailbreak in {int(n+1)}-th iteration.\", verbose)\n",
    "                opt_para_inquires[i] = para_inq.strip() if para_inq else ''  # store the optimal para_inquiry for the successful jailbreak.\n",
    "                asr_list[i] = is_jailbroken\n",
    "                hscore_list[i] = hscore\n",
    "                q4j_list.append(num_query4jailbreak) # count the query when jailbreak is successful. (or use 'n+1').\n",
    "                pdict['para_inq_old'] = 'NA'\n",
    "                pdict['feedback'] = 'NA'\n",
    "                break\n",
    "    q4j_mean = sum(q4j_list)/len(q4j_list) if q4j_list else 0\n",
    "    return opt_para_inquires, asr_list, hscore_list, q4j_mean\n",
    "\n",
    "# Load data\n",
    "data_name = 'jambench_behaviors' # advbench_behaviors/harmbench_behaviors/jailbreakbench_behaviors/jambench_behaviors\n",
    "infile_path = f'../data/{data_name}.csv'\n",
    "data_df = pd.read_csv(infile_path, header=None) # read as dataframe\n",
    "data_los = data_df.astype(str).apply(lambda x: ' '.join(x), axis=1).tolist() # convert to list of string\n",
    "# Subsample instances (for debug)\n",
    "inquires_list = subsample_data(data_los, is_sampled, num_sample, seed=42)\n",
    "\n",
    "# Perform Rad Teaming - explore the vulnerability via intent jailbreak\n",
    "opt_para_inquires, asr_list, hscore_list, q4j_mean = intent_jailbreak(inquires_list, num_iter, verbose=True)\n",
    "\n",
    "# Evaluation\n",
    "asr = compute_asr(asr_list)\n",
    "hscore = compute_success_hscore_mean(asr_list, hscore_list)\n",
    "print(f\"ASR: {asr*100:.2f}%\")\n",
    "print(f\"Hscore: {hscore:.2f}\")\n",
    "print(f\"The average number of queries used for successful jailbreaks: {q4j_mean:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
